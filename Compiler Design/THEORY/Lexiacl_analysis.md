![Capture](https://user-images.githubusercontent.com/89020930/160384582-28267b35-00e7-46d1-8cac-c33f6a3d082b.JPG)


## It is also known as tokenixation and the program which is dividing is known as lexer,tokenizer,scanner etc

# Tokens include
- > identifier  - those which programmer is defining ex x,y
- > seperators - punctuators ex (,),;
- > keywords - which are already defined in the programming language ex int,auto
- > operators - < , > + 
- > constants -> sometimes true/ false and literals 
- > special characters - $ ,& etc
- > "" inside these commas all the value will be counted as one 

> ## we use finite automata in it  -> application of finite automata is to convert any program  into convert into tokens 
